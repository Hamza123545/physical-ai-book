if(void 0===__webpack_require__)var __webpack_require__={};(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[6007],{3277:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"appendices/appendix-b-computer-vision-fundamentals/lesson-05-vision-navigation","title":"Lesson 3.5: Vision-Based Navigation","description":"Integrate vision processing with path planning for autonomous navigation","source":"@site/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-05-vision-navigation.md","sourceDirName":"appendices/appendix-b-computer-vision-fundamentals","slug":"/appendices/appendix-b-computer-vision-fundamentals/lesson-05-vision-navigation","permalink":"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-05-vision-navigation","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"navigation","permalink":"/physical-ai-book/docs/tags/navigation"},{"inline":true,"label":"path-planning","permalink":"/physical-ai-book/docs/tags/path-planning"},{"inline":true,"label":"obstacle-avoidance","permalink":"/physical-ai-book/docs/tags/obstacle-avoidance"},{"inline":true,"label":"visual-servoing","permalink":"/physical-ai-book/docs/tags/visual-servoing"}],"version":"current","frontMatter":{"title":"Lesson 3.5: Vision-Based Navigation","description":"Integrate vision processing with path planning for autonomous navigation","chapter":3,"lesson":5,"estimated_time":70,"cefr_level":"B2","blooms_level":"Evaluate","digcomp_level":6,"generated_by":"claude-sonnet-4-5-20250929","source_spec":"specs/002-physical-ai-textbook/spec.md","created":"2025-11-29","last_modified":"2025-11-29","git_author":"hswat","workflow":"/sp.implement","version":"1.0","prerequisites":["chapter-03-lesson-03","chapter-03-lesson-04"],"has_interactive_python":true,"interactive_python_count":4,"has_try_with_ai":true,"try_with_ai_count":2,"tags":["navigation","path-planning","obstacle-avoidance","visual-servoing"]},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 3.4: Depth Perception and Obstacles","permalink":"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-04-depth-perception"},"next":{"title":"Chapter 3 Quiz: Computer Vision for Robotics","permalink":"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/quiz"}}');var s=n(4848),a=n(8453);const o={title:"Lesson 3.5: Vision-Based Navigation",description:"Integrate vision processing with path planning for autonomous navigation",chapter:3,lesson:5,estimated_time:70,cefr_level:"B2",blooms_level:"Evaluate",digcomp_level:6,generated_by:"claude-sonnet-4-5-20250929",source_spec:"specs/002-physical-ai-textbook/spec.md",created:"2025-11-29",last_modified:"2025-11-29",git_author:"hswat",workflow:"/sp.implement",version:"1.0",prerequisites:["chapter-03-lesson-03","chapter-03-lesson-04"],has_interactive_python:!0,interactive_python_count:4,has_try_with_ai:!0,try_with_ai_count:2,tags:["navigation","path-planning","obstacle-avoidance","visual-servoing"]},r="Lesson 3.5: Vision-Based Navigation",l={},c=[{value:"\ud83c\udfaf Learning Objectives",id:"-learning-objectives",level:2},{value:"\ud83d\udcda Prerequisites",id:"-prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"1. Visual Servoing",id:"1-visual-servoing",level:2},{value:"2. Bug Algorithm",id:"2-bug-algorithm",level:2},{value:"3. Exercises",id:"3-exercises",level:2},{value:"Exercise 3.5.1: Compute Heading to Target",id:"exercise-351-compute-heading-to-target",level:3},{value:"Exercise 3.5.2: Detect Obstacles in Path",id:"exercise-352-detect-obstacles-in-path",level:3},{value:"Exercise 3.5.3: Bug Algorithm Planner",id:"exercise-353-bug-algorithm-planner",level:3},{value:"Exercise 3.5.4: Complete Navigation Challenge",id:"exercise-354-complete-navigation-challenge",level:3},{value:"4. Try With AI",id:"4-try-with-ai",level:2},{value:"TryWithAI 3.5.1: Navigation Strategy",id:"trywithai-351-navigation-strategy",level:3},{value:"TryWithAI 3.5.2: Test Edge Cases",id:"trywithai-352-test-edge-cases",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const t={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",...(0,a.R)(),...e.components},{InteractivePython:n,LearningObjectives:i,Prerequisites:o,TryWithAI:r}=t;return n||h("InteractivePython",!0),i||h("LearningObjectives",!0),o||h("Prerequisites",!0),r||h("TryWithAI",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"lesson-35-vision-based-navigation",children:"Lesson 3.5: Vision-Based Navigation"})}),"\n",(0,s.jsx)(t.h2,{id:"-learning-objectives",children:"\ud83c\udfaf Learning Objectives"}),"\n",(0,s.jsx)(i,{cefr_level:"B2",objectives:[{text:"Compute heading to target from visual features",blooms_level:"Apply",assessment_method:"Heading computation exercise"},{text:"Detect obstacles in navigation path",blooms_level:"Apply",assessment_method:"Obstacle detection exercise"},{text:"Implement bug algorithm for path planning",blooms_level:"Apply",assessment_method:"Path planning exercise"},{text:"Complete navigation challenge with 90%+ success",blooms_level:"Evaluate",assessment_method:"Integration exercise"}]}),"\n",(0,s.jsx)(t.h2,{id:"-prerequisites",children:"\ud83d\udcda Prerequisites"}),"\n",(0,s.jsx)(o,{prerequisites:[{lessonId:"chapter-03-lesson-03",title:"Lesson 3.3: Object Detection",link:"/docs/chapter-03/lesson-03-object-detection"},{lessonId:"chapter-03-lesson-04",title:"Lesson 3.4: Depth Perception",link:"/docs/chapter-03/lesson-04-depth-perception"}]}),"\n",(0,s.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(t.p,{children:"This lesson integrates everything: detect goals, avoid obstacles, plan paths."}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Time"}),": 70 minutes"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"1-visual-servoing",children:"1. Visual Servoing"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Visual servoing"}),": Control robot using visual feedback."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"2-bug-algorithm",children:"2. Bug Algorithm"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Bug algorithm"}),": Simple reactive navigation:"]}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsx)(t.li,{children:"Move toward goal"}),"\n",(0,s.jsx)(t.li,{children:"If obstacle, follow boundary"}),"\n",(0,s.jsx)(t.li,{children:"When clear path to goal, resume direct approach"}),"\n"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"3-exercises",children:"3. Exercises"}),"\n",(0,s.jsx)(t.h3,{id:"exercise-351-compute-heading-to-target",children:"Exercise 3.5.1: Compute Heading to Target"}),"\n",(0,s.jsx)(n,{id:"ex-3-5-1",title:"Visual Heading Estimation",starterCode:'import numpy as np\n\ndef compute_heading_to_target(image, target_color_range):\n  """Compute heading angle to colored target."""\n  # TODO: Segment target by color\n  # Compute centroid\n  # Return heading angle (left/right of center)\n  pass\n\n# Test\nimg = np.zeros((100, 200, 3), dtype=np.uint8)\nimg[40:60, 150:170] = [255, 0, 0]  # Red target on right\n\nheading = compute_heading_to_target(img, ([200,0,0], [255,50,50]))\nprint(f"Heading: {heading:.1f} degrees")\nprint(f"Expected: positive (turn right)")\n',hints:["Segment by color","Find centroid x-coordinate","Center of image: img.shape[1] / 2","Heading = (centroid_x - center_x) * scale_factor"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h3,{id:"exercise-352-detect-obstacles-in-path",children:"Exercise 3.5.2: Detect Obstacles in Path"}),"\n",(0,s.jsx)(n,{id:"ex-3-5-2",title:"Path Obstacle Detection",starterCode:'import numpy as np\n\ndef obstacles_in_path(depth_image, safe_distance=1.5, path_width=0.5):\n  """Check if path ahead is clear."""\n  # TODO: Extract center region (path)\n  # Check if any depth < safe_distance\n  # Return boolean (True = blocked)\n  pass\n\n# Test\ndepth = np.ones((100, 100)) * 3.0\ndepth[40:60, 45:55] = 0.8  # Obstacle in center\n\nblocked = obstacles_in_path(depth, safe_distance=1.5)\nprint(f"Path blocked: {blocked}")\nprint(f"Expected: True")\n',hints:["height, width = depth_image.shape","path_start = width//2 - path_width//2","path_end = width//2 + path_width//2","path_region = depth_image[:, path_start:path_end]","return np.any(path_region < safe_distance)"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h3,{id:"exercise-353-bug-algorithm-planner",children:"Exercise 3.5.3: Bug Algorithm Planner"}),"\n",(0,s.jsx)(n,{id:"ex-3-5-3",title:"Bug Algorithm Navigation",starterCode:'import numpy as np\n\ndef bug_algorithm_step(robot_pos, goal_pos, occupancy_grid):\n  """Compute next move using bug algorithm."""\n  # TODO: If direct path clear, move toward goal\n  # Else, follow obstacle boundary\n  pass\n\n# Test\ngrid = np.zeros((50, 50))\ngrid[20:30, 20:30] = 1  # Obstacle\n\nrobot = (10, 10)\ngoal = (40, 40)\n\nnext_pos = bug_algorithm_step(robot, goal, grid)\nprint(f"Next position: {next_pos}")\n',hints:["Compute direction to goal","Check if path clear using occupancy grid","If clear: move toward goal","Else: move along obstacle edge"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h3,{id:"exercise-354-complete-navigation-challenge",children:"Exercise 3.5.4: Complete Navigation Challenge"}),"\n",(0,s.jsx)(n,{id:"ex-3-5-4",title:"Navigation Challenge (90%+ Success)",starterCode:'import numpy as np\nimport matplotlib.pyplot as plt\n\ndef navigate_to_goal(start, goal, obstacles, max_steps=1000):\n  """Navigate from start to goal avoiding obstacles.\n\n  Returns:\n      path: List of positions\n      success: Boolean (reached goal)\n  """\n  # TODO: Integrate all vision techniques\n  # 1. Detect obstacles\n  # 2. Plan path\n  # 3. Move step-by-step\n  # Return path and success flag\n  pass\n\n# Test scenarios\nscenarios = [\n  {"start": (5, 5), "goal": (45, 45), "obstacles": []},\n  {"start": (5, 5), "goal": (45, 45), "obstacles": [(25, 25, 10)]},  # (x, y, radius)\n]\n\nsuccess_count = 0\nfor scenario in scenarios:\n  path, success = navigate_to_goal(**scenario)\n  if success:\n      success_count += 1\n\nprint(f"Success rate: {success_count / len(scenarios) * 100:.1f}%")\nprint(f"Target: 90%+")\n',hints:["Use bug algorithm for each step","Track path","Check goal reached: distance < threshold","Return (path, True) if reached, (path, False) if max_steps exceeded"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"4-try-with-ai",children:"4. Try With AI"}),"\n",(0,s.jsx)(t.h3,{id:"trywithai-351-navigation-strategy",children:"TryWithAI 3.5.1: Navigation Strategy"}),"\n",(0,s.jsx)(r,{id:"tryai-3-5-1",title:"Design Navigation Strategy",role:"Copilot",scenario:"Your bug algorithm gets stuck in local minima (U-shaped obstacles).",yourTask:"Implement Exercise 3.5.3. Test with U-shaped obstacle. Observe failure.",aiPromptTemplate:"My bug algorithm navigation gets stuck in U-shaped obstacles. Here's my code: [paste]. Can you help me: (1) Understand why it fails? (2) Suggest improvements (random walk, potential fields)? (3) When should I use A* instead of bug algorithm?",successCriteria:["You understand bug algorithm limitations","You know alternatives (A*, potential fields, RRT)","You can choose appropriate planner for scenario"],reflectionQuestions:["What's the trade-off between simple (bug) and complex (A*) planners?","How do you detect local minima?","When is reactive vs. deliberative planning better?"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h3,{id:"trywithai-352-test-edge-cases",children:"TryWithAI 3.5.2: Test Edge Cases"}),"\n",(0,s.jsx)(r,{id:"tryai-3-5-2",title:"Validate Navigation Robustness",role:"Evaluator",scenario:"You need to test your navigator with edge cases before deployment.",yourTask:"Complete Exercise 3.5.4. Design 10 test scenarios (easy to impossible).",aiPromptTemplate:"I've implemented vision-based navigation. Here's my code: [paste]. I achieve [X]% success on basic tests. Can you review and suggest edge case tests? I want to test: narrow passages, dense obstacles, unreachable goals, sensor noise. How do I systematically validate?",successCriteria:["You have comprehensive test suite","You achieve 90%+ on realistic scenarios","You understand failure modes"],reflectionQuestions:["What constitutes a 'fair' test scenario?","How do you balance safety vs. efficiency?","When should the robot admit failure?"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Key Takeaways"}),":"]}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Visual Servoing"}),": Control using visual feedback"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Bug Algorithm"}),": Simple reactive navigation"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Integration"}),": Combine vision, planning, control"]}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"\ud83c\udf89 Chapter 3 Complete!"})," You can now implement vision-based navigation with obstacle detection."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"What's Next"}),": Take the ",(0,s.jsx)(t.a,{href:"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/quiz",children:"Chapter 3 Quiz"}),"!"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Estimated completion time"}),": 70 minutes | ",(0,s.jsx)(t.strong,{children:"Difficulty"}),": B2"]})]})}function p(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}function h(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},8453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>r});var i=n(6540);const s={},a=i.createContext(s);function o(e){const t=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(a.Provider,{value:t},e.children)}}}]);