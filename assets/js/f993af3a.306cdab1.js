if(void 0===__webpack_require__)var __webpack_require__={};(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[2677],{1190:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"appendices/appendix-b-computer-vision-fundamentals/index","title":"Appendix B: Computer Vision Fundamentals for Robotics","description":"Fundamental computer vision techniques for robot perception - image processing, edge detection, object detection, and vision-based navigation","source":"@site/docs/appendices/appendix-b-computer-vision-fundamentals/index.md","sourceDirName":"appendices/appendix-b-computer-vision-fundamentals","slug":"/appendices/appendix-b-computer-vision-fundamentals/","permalink":"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":101,"frontMatter":{"title":"Appendix B: Computer Vision Fundamentals for Robotics","description":"Fundamental computer vision techniques for robot perception - image processing, edge detection, object detection, and vision-based navigation","sidebar_position":101},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 2.5: Jacobians and Velocities","permalink":"/physical-ai-book/docs/appendices/appendix-a-advanced-kinematics/lesson-05-jacobians-velocities"},"next":{"title":"Lesson 3.1: Image Representation and Processing","permalink":"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-01-image-representation"}}');var o=i(4848),t=i(8453);const a={title:"Appendix B: Computer Vision Fundamentals for Robotics",description:"Fundamental computer vision techniques for robot perception - image processing, edge detection, object detection, and vision-based navigation",sidebar_position:101},r="Appendix B: Computer Vision Fundamentals for Robotics",d={},c=[{value:"Overview",id:"overview",level:2},{value:"Lessons",id:"lessons",level:2},{value:"Lesson B.1: Image Representation and Processing",id:"lesson-b1-image-representation-and-processing",level:3},{value:"Lesson B.2: Edge and Corner Detection",id:"lesson-b2-edge-and-corner-detection",level:3},{value:"Lesson B.3: Object Detection and Tracking",id:"lesson-b3-object-detection-and-tracking",level:3},{value:"Lesson B.4: Depth Perception and Obstacles",id:"lesson-b4-depth-perception-and-obstacles",level:3},{value:"Lesson B.5: Vision-Based Navigation",id:"lesson-b5-vision-based-navigation",level:3},{value:"Assessment",id:"assessment",level:2},{value:"Appendix B Quiz",id:"appendix-b-quiz",level:3},{value:"Prerequisites",id:"prerequisites",level:2}];function l(e){const n={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"appendix-b-computer-vision-fundamentals-for-robotics",children:"Appendix B: Computer Vision Fundamentals for Robotics"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Note"}),": This content was originally Chapter 3. It has been moved to Appendix B as supplementary material. The core Module 2 content (Gazebo & Unity Simulation) is now in Chapter 3."]}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsxs)(n.p,{children:["Robots need to see and understand their environment to navigate, manipulate objects, and interact with the world. ",(0,o.jsx)(n.strong,{children:"Computer vision"})," gives robots the ability to process camera images and extract meaningful information."]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"What you'll master:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Image representation and processing (grayscale, thresholding, filtering)"}),"\n",(0,o.jsx)(n.li,{children:"Edge and corner detection algorithms"}),"\n",(0,o.jsx)(n.li,{children:"Object detection, tracking, and centroid computation"}),"\n",(0,o.jsx)(n.li,{children:"Depth perception and obstacle detection"}),"\n",(0,o.jsx)(n.li,{children:"Vision-based navigation with path planning"}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"lessons",children:"Lessons"}),"\n",(0,o.jsx)(n.h3,{id:"lesson-b1-image-representation-and-processing",children:(0,o.jsx)(n.a,{href:"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-01-image-representation",children:"Lesson B.1: Image Representation and Processing"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Duration"}),": 50 minutes | ",(0,o.jsx)(n.strong,{children:"Difficulty"}),": B1+ (Upper Intermediate)"]}),"\n",(0,o.jsx)(n.p,{children:"Learn how images are represented as NumPy arrays. Perform fundamental operations: RGB to grayscale conversion, thresholding, and binary segmentation."}),"\n",(0,o.jsx)(n.h3,{id:"lesson-b2-edge-and-corner-detection",children:(0,o.jsx)(n.a,{href:"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-02-edge-detection",children:"Lesson B.2: Edge and Corner Detection"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Duration"}),": 60 minutes | ",(0,o.jsx)(n.strong,{children:"Difficulty"}),": B2 (Advanced)"]}),"\n",(0,o.jsx)(n.p,{children:"Detect edges using gradient operators (Sobel, Canny). Find corners for feature detection and matching."}),"\n",(0,o.jsx)(n.h3,{id:"lesson-b3-object-detection-and-tracking",children:(0,o.jsx)(n.a,{href:"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-03-object-detection",children:"Lesson B.3: Object Detection and Tracking"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Duration"}),": 70 minutes | ",(0,o.jsx)(n.strong,{children:"Difficulty"}),": B2 (Advanced)"]}),"\n",(0,o.jsx)(n.p,{children:"Segment objects by color, compute centroids, and track objects across video frames."}),"\n",(0,o.jsx)(n.h3,{id:"lesson-b4-depth-perception-and-obstacles",children:(0,o.jsx)(n.a,{href:"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-04-depth-perception",children:"Lesson B.4: Depth Perception and Obstacles"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Duration"}),": 60 minutes | ",(0,o.jsx)(n.strong,{children:"Difficulty"}),": B2 (Advanced)"]}),"\n",(0,o.jsx)(n.p,{children:"Process depth images to detect obstacles, build occupancy grids, and find navigable free space."}),"\n",(0,o.jsx)(n.h3,{id:"lesson-b5-vision-based-navigation",children:(0,o.jsx)(n.a,{href:"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-05-vision-navigation",children:"Lesson B.5: Vision-Based Navigation"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Duration"}),": 70 minutes | ",(0,o.jsx)(n.strong,{children:"Difficulty"}),": B2 (Advanced)"]}),"\n",(0,o.jsx)(n.p,{children:"Integrate vision processing with path planning. Implement complete navigation that detects obstacles and reaches goals."}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"assessment",children:"Assessment"}),"\n",(0,o.jsx)(n.h3,{id:"appendix-b-quiz",children:(0,o.jsx)(n.a,{href:"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/quiz",children:"Appendix B Quiz"})}),"\n",(0,o.jsx)(n.p,{children:"Test your understanding with a comprehensive quiz covering all lessons."}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(n.p,{children:["This appendix builds on ",(0,o.jsx)(n.strong,{children:"Chapter 1: Introduction to Physical AI"}),". You should be comfortable with:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"NumPy arrays and operations"}),"\n",(0,o.jsx)(n.li,{children:"Matplotlib plotting"}),"\n",(0,o.jsx)(n.li,{children:"Basic Python programming"}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Note"}),": This content is supplementary. For the core course, see Chapter 3: Gazebo & Unity Simulation."]})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>r});var s=i(6540);const o={},t=s.createContext(o);function a(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);