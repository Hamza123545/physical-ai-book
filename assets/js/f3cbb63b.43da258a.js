if(void 0===__webpack_require__)var __webpack_require__={};(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[18],{1220:(e,s,i)=>{i.r(s),i.d(s,{assets:()=>r,contentTitle:()=>a,default:()=>p,frontMatter:()=>o,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"appendices/appendix-b-computer-vision-fundamentals/lesson-04-depth-perception","title":"Lesson 3.4: Depth Perception and Obstacles","description":"Process depth images to detect obstacles and build occupancy grids","source":"@site/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-04-depth-perception.md","sourceDirName":"appendices/appendix-b-computer-vision-fundamentals","slug":"/appendices/appendix-b-computer-vision-fundamentals/lesson-04-depth-perception","permalink":"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-04-depth-perception","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"depth","permalink":"/physical-ai-book/docs/tags/depth"},{"inline":true,"label":"obstacles","permalink":"/physical-ai-book/docs/tags/obstacles"},{"inline":true,"label":"occupancy-grid","permalink":"/physical-ai-book/docs/tags/occupancy-grid"},{"inline":true,"label":"3d-vision","permalink":"/physical-ai-book/docs/tags/3-d-vision"}],"version":"current","frontMatter":{"title":"Lesson 3.4: Depth Perception and Obstacles","description":"Process depth images to detect obstacles and build occupancy grids","chapter":3,"lesson":4,"estimated_time":60,"cefr_level":"B2","blooms_level":"Apply","digcomp_level":5,"generated_by":"claude-sonnet-4-5-20250929","source_spec":"specs/002-physical-ai-textbook/spec.md","created":"2025-11-29","last_modified":"2025-11-29","git_author":"hswat","workflow":"/sp.implement","version":"1.0","prerequisites":["chapter-03-lesson-01"],"has_interactive_python":true,"interactive_python_count":3,"has_try_with_ai":true,"try_with_ai_count":1,"tags":["depth","obstacles","occupancy-grid","3d-vision"]},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 3.3: Object Detection and Tracking","permalink":"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-03-object-detection"},"next":{"title":"Lesson 3.5: Vision-Based Navigation","permalink":"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-05-vision-navigation"}}');var t=i(4848),c=i(8453);const o={title:"Lesson 3.4: Depth Perception and Obstacles",description:"Process depth images to detect obstacles and build occupancy grids",chapter:3,lesson:4,estimated_time:60,cefr_level:"B2",blooms_level:"Apply",digcomp_level:5,generated_by:"claude-sonnet-4-5-20250929",source_spec:"specs/002-physical-ai-textbook/spec.md",created:"2025-11-29",last_modified:"2025-11-29",git_author:"hswat",workflow:"/sp.implement",version:"1.0",prerequisites:["chapter-03-lesson-01"],has_interactive_python:!0,interactive_python_count:3,has_try_with_ai:!0,try_with_ai_count:1,tags:["depth","obstacles","occupancy-grid","3d-vision"]},a="Lesson 3.4: Depth Perception and Obstacles",r={},l=[{value:"\ud83c\udfaf Learning Objectives",id:"-learning-objectives",level:2},{value:"\ud83d\udcda Prerequisites",id:"-prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"1. Depth Images",id:"1-depth-images",level:2},{value:"2. Obstacle Detection",id:"2-obstacle-detection",level:2},{value:"3. Occupancy Grids",id:"3-occupancy-grids",level:2},{value:"4. Exercises",id:"4-exercises",level:2},{value:"Exercise 3.4.1: Detect Obstacles from Depth",id:"exercise-341-detect-obstacles-from-depth",level:3},{value:"Exercise 3.4.2: Build Occupancy Grid",id:"exercise-342-build-occupancy-grid",level:3},{value:"Exercise 3.4.3: Find Free Space",id:"exercise-343-find-free-space",level:3},{value:"5. Try With AI",id:"5-try-with-ai",level:2},{value:"TryWithAI 3.4.1: Obstacle Detection Optimization",id:"trywithai-341-obstacle-detection-optimization",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const s={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,c.R)(),...e.components},{InteractivePython:i,LearningObjectives:n,Prerequisites:o,TryWithAI:a}=s;return i||h("InteractivePython",!0),n||h("LearningObjectives",!0),o||h("Prerequisites",!0),a||h("TryWithAI",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"lesson-34-depth-perception-and-obstacles",children:"Lesson 3.4: Depth Perception and Obstacles"})}),"\n",(0,t.jsx)(s.h2,{id:"-learning-objectives",children:"\ud83c\udfaf Learning Objectives"}),"\n",(0,t.jsx)(n,{cefr_level:"B2",objectives:[{text:"Process depth images to detect obstacles",blooms_level:"Apply",assessment_method:"Obstacle detection exercise"},{text:"Build occupancy grids from depth data",blooms_level:"Apply",assessment_method:"Occupancy grid exercise"},{text:"Identify free space for navigation",blooms_level:"Apply",assessment_method:"Free space detection exercise"}]}),"\n",(0,t.jsx)(s.h2,{id:"-prerequisites",children:"\ud83d\udcda Prerequisites"}),"\n",(0,t.jsx)(o,{prerequisites:[{lessonId:"chapter-03-lesson-01",title:"Lesson 3.1: Image Representation",link:"/docs/chapter-03/lesson-01-image-representation"}]}),"\n",(0,t.jsx)(s.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Depth cameras"})," (like Kinect, RealSense) provide distance to each pixel. This enables:"]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Obstacle detection"}),"\n",(0,t.jsx)(s.li,{children:"3D mapping"}),"\n",(0,t.jsx)(s.li,{children:"Safe navigation"}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Time"}),": 60 minutes"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"1-depth-images",children:"1. Depth Images"}),"\n",(0,t.jsx)(s.p,{children:"Depth image: 2D array where each pixel value = distance (in meters or millimeters)."}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"depth_image = np.array([\n    [1.0, 1.5, 2.0],  # Row 1: distances\n    [0.8, 1.2, 1.8],  # Row 2\n])\n"})}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"2-obstacle-detection",children:"2. Obstacle Detection"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Obstacles"}),": Pixels closer than safe distance threshold."]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:"obstacle_mask = depth_image < safe_distance\n"})}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"3-occupancy-grids",children:"3. Occupancy Grids"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Occupancy grid"}),": Top-down map showing occupied/free cells."]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"4-exercises",children:"4. Exercises"}),"\n",(0,t.jsx)(s.h3,{id:"exercise-341-detect-obstacles-from-depth",children:"Exercise 3.4.1: Detect Obstacles from Depth"}),"\n",(0,t.jsx)(i,{id:"ex-3-4-1",title:"Obstacle Detection",starterCode:'import numpy as np\nimport matplotlib.pyplot as plt\n\ndef detect_obstacles(depth_image, safe_distance=1.5):\n  """Detect obstacles closer than safe_distance."""\n  # TODO: Return binary mask of obstacles\n  pass\n\n# Test\ndepth = np.random.uniform(0.5, 3.0, (50, 50))\ndepth[20:30, 20:30] = 0.8  # Close obstacle\n\nobstacles = detect_obstacles(depth, safe_distance=1.5)\nplt.imshow(obstacles, cmap=\'gray\')\nplt.title(\'Obstacles (white = danger)\')\nplt.show()\n',hints:["obstacles = (depth_image < safe_distance)","Return obstacles.astype(np.uint8) * 255"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h3,{id:"exercise-342-build-occupancy-grid",children:"Exercise 3.4.2: Build Occupancy Grid"}),"\n",(0,t.jsx)(i,{id:"ex-3-4-2",title:"Occupancy Grid from Depth",starterCode:'import numpy as np\n\ndef depth_to_occupancy_grid(depth_image, cell_size=0.1, max_range=5.0):\n  """Convert depth image to occupancy grid."""\n  # TODO: Project depth pixels to grid coordinates\n  # Mark occupied cells\n  pass\n\n# Test\ndepth = np.random.uniform(1.0, 4.0, (100, 100))\ngrid = depth_to_occupancy_grid(depth, cell_size=0.2)\nprint(f"Grid shape: {grid.shape}")\n',hints:["grid_size = int(max_range / cell_size)","grid = np.zeros((grid_size, grid_size))","For each depth pixel: compute grid cell (x, y)","grid[y, x] = 1  # occupied"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h3,{id:"exercise-343-find-free-space",children:"Exercise 3.4.3: Find Free Space"}),"\n",(0,t.jsx)(i,{id:"ex-3-4-3",title:"Free Space Detection",starterCode:'import numpy as np\n\ndef find_free_space(occupancy_grid):\n  """Find largest free space region."""\n  # TODO: Identify connected free regions\n  # Return largest region\n  pass\n\n# Test\ngrid = np.random.randint(0, 2, (50, 50))\nfree = find_free_space(grid)\nprint(f"Largest free region size: {np.sum(free)}")\n',hints:["Free cells: grid == 0","Use connected component labeling","Find component with most pixels"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"5-try-with-ai",children:"5. Try With AI"}),"\n",(0,t.jsx)(s.h3,{id:"trywithai-341-obstacle-detection-optimization",children:"TryWithAI 3.4.1: Obstacle Detection Optimization"}),"\n",(0,t.jsx)(a,{id:"tryai-3-4-1",title:"Optimize Depth Processing",role:"Copilot",scenario:"Your depth processing is too slow for real-time navigation (need 30 FPS).",yourTask:"Profile exercises 3.4.1 and 3.4.2. Measure execution time for 640x480 depth images.",aiPromptTemplate:"My depth obstacle detection takes [X] ms for 640x480 images. I need < 33ms for 30 FPS. Here's my code: [paste]. Can you help optimize? Should I downsample? Use GPU? What's the computational bottleneck?",successCriteria:["You can profile Python code","You understand downsampling trade-offs","Your code runs in real-time"],reflectionQuestions:["How does resolution affect obstacle detection accuracy?","When should you use GPU acceleration?","What's the minimum viable resolution for navigation?"]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Key Takeaways"}),":"]}),"\n",(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Depth Images"}),": Distance to each pixel"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Obstacles"}),": Pixels closer than threshold"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Occupancy Grids"}),": Top-down map of environment"]}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"What's Next"}),": ",(0,t.jsx)(s.a,{href:"/physical-ai-book/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-05-vision-navigation",children:"Lesson 3.5: Vision-Based Navigation"})]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Estimated completion time"}),": 60 minutes | ",(0,t.jsx)(s.strong,{children:"Difficulty"}),": B2"]})]})}function p(e={}){const{wrapper:s}={...(0,c.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}function h(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},8453:(e,s,i)=>{i.d(s,{R:()=>o,x:()=>a});var n=i(6540);const t={},c=n.createContext(t);function o(e){const s=n.useContext(c);return n.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function a(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),n.createElement(c.Provider,{value:s},e.children)}}}]);