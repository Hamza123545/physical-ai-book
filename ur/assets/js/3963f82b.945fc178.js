if(void 0===__webpack_require__)var __webpack_require__={};(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[1464],{2560:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"chapter-05/lesson-05-mpc","title":"Lesson 5.5: Model Predictive Control","description":"Learn MPC for optimal trajectory tracking with constraints","source":"@site/i18n/ur/docusaurus-plugin-content-docs/current/chapter-05/lesson-05-mpc.md","sourceDirName":"chapter-05","slug":"/chapter-05/lesson-05-mpc","permalink":"/physical-ai-book/ur/docs/chapter-05/lesson-05-mpc","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"mpc","permalink":"/physical-ai-book/ur/docs/tags/mpc"},{"inline":true,"label":"optimization","permalink":"/physical-ai-book/ur/docs/tags/optimization"},{"inline":true,"label":"constraints","permalink":"/physical-ai-book/ur/docs/tags/constraints"},{"inline":true,"label":"receding-horizon","permalink":"/physical-ai-book/ur/docs/tags/receding-horizon"}],"version":"current","frontMatter":{"title":"Lesson 5.5: Model Predictive Control","description":"Learn MPC for optimal trajectory tracking with constraints","chapter":5,"lesson":5,"estimated_time":60,"cefr_level":"B2","blooms_level":"Apply","digcomp_level":6,"generated_by":"claude-sonnet-4-5-20250929","source_spec":"specs/002-physical-ai-textbook/spec.md","created":"2025-11-29","last_modified":"2025-11-29","git_author":"claude","workflow":"/sp.implement","version":"1.0","prerequisites":["chapter-05/lesson-04-feedback-control"],"has_interactive_python":true,"interactive_python_count":3,"has_try_with_ai":true,"try_with_ai_count":1,"tags":["mpc","optimization","constraints","receding-horizon"]},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 5.4: Feedback Control","permalink":"/physical-ai-book/ur/docs/chapter-05/lesson-04-feedback-control"},"next":{"title":"Lesson 5.6: Nav2 - Path Planning Framework","permalink":"/physical-ai-book/ur/docs/chapter-05/lesson-06-nav2-architecture"}}');var r=t(4848),s=t(8453);const o={title:"Lesson 5.5: Model Predictive Control",description:"Learn MPC for optimal trajectory tracking with constraints",chapter:5,lesson:5,estimated_time:60,cefr_level:"B2",blooms_level:"Apply",digcomp_level:6,generated_by:"claude-sonnet-4-5-20250929",source_spec:"specs/002-physical-ai-textbook/spec.md",created:"2025-11-29",last_modified:"2025-11-29",git_author:"claude",workflow:"/sp.implement",version:"1.0",prerequisites:["chapter-05/lesson-04-feedback-control"],has_interactive_python:!0,interactive_python_count:3,has_try_with_ai:!0,try_with_ai_count:1,tags:["mpc","optimization","constraints","receding-horizon"]},a="Lesson 5.5: Model Predictive Control",c={},l=[{value:"\ud83c\udfaf Learning Objectives",id:"-learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"1. MPC Concept",id:"1-mpc-concept",level:2},{value:"Receding Horizon",id:"receding-horizon",level:3},{value:"2. MPC Formulation",id:"2-mpc-formulation",level:2},{value:"Problem Setup",id:"problem-setup",level:3},{value:"3. MPC vs PID",id:"3-mpc-vs-pid",level:2},{value:"4. Implementation Steps",id:"4-implementation-steps",level:2},{value:"1. Discretize System",id:"1-discretize-system",level:3},{value:"2. Define Cost Function",id:"2-define-cost-function",level:3},{value:"3. Solve Optimization",id:"3-solve-optimization",level:3},{value:"4. Apply &amp; Repeat",id:"4-apply--repeat",level:3},{value:"5. Exercises",id:"5-exercises",level:2},{value:"Exercise 5.5.1: Predict Future States",id:"exercise-551-predict-future-states",level:3},{value:"Exercise 5.5.2: Simple MPC (Unconstrained)",id:"exercise-552-simple-mpc-unconstrained",level:3},{value:"Exercise 5.5.3: MPC with Constraints",id:"exercise-553-mpc-with-constraints",level:3},{value:"6. Try With AI",id:"6-try-with-ai",level:2},{value:"TryWithAI 5.5.1: When to Use MPC",id:"trywithai-551-when-to-use-mpc",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components},{InteractivePython:t,LearningObjectives:i,TryWithAI:o}=n;return t||p("InteractivePython",!0),i||p("LearningObjectives",!0),o||p("TryWithAI",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"lesson-55-model-predictive-control",children:"Lesson 5.5: Model Predictive Control"})}),"\n",(0,r.jsx)(n.h2,{id:"-learning-objectives",children:"\ud83c\udfaf Learning Objectives"}),"\n",(0,r.jsx)(i,{cefr_level:"B2",objectives:[{text:"Understand MPC's receding horizon optimization principle",blooms_level:"Understand",assessment_method:"Quiz questions"},{text:"Implement basic MPC for trajectory tracking with constraints",blooms_level:"Apply",assessment_method:"Interactive Python exercises"},{text:"Compare MPC vs PID trade-offs for constrained systems",blooms_level:"Analyze",assessment_method:"TryWithAI exercises"}]}),"\n",(0,r.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"PID"})," reacts to current error. ",(0,r.jsx)(n.strong,{children:"MPC"})," plans ahead, optimizing over a future horizon while respecting constraints."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Why MPC?"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Handle constraints (max velocity, acceleration, force)"}),"\n",(0,r.jsx)(n.li,{children:"Predictive (anticipate future behavior)"}),"\n",(0,r.jsx)(n.li,{children:"Optimal (minimize cost function)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Used in"}),": Self-driving cars, drones, walking robots, industrial automation."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Time"}),": 60 minutes"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"1-mpc-concept",children:"1. MPC Concept"}),"\n",(0,r.jsx)(n.h3,{id:"receding-horizon",children:"Receding Horizon"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Idea"}),": At each time step:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Predict"})," system behavior over horizon N steps"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Optimize"})," control sequence to minimize cost"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Apply"})," only first control action"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Repeat"}),' at next time step (horizon "recedes")']}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Analogy"}),": Driving a car - you plan the next few seconds, execute immediately, then replan."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"2-mpc-formulation",children:"2. MPC Formulation"}),"\n",(0,r.jsx)(n.h3,{id:"problem-setup",children:"Problem Setup"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"System model"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"x[k+1] = A*x[k] + B*u[k]  (discrete-time dynamics)\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Cost function"})," (minimize over horizon N):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"J = \u03a3 (||x[k] - x_ref||\xb2 + ||u[k]||\xb2)\n    k=0 to N-1\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Constraints"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"u_min \u2264 u[k] \u2264 u_max  (control limits)\nx_min \u2264 x[k] \u2264 x_max  (state limits)\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solve"}),": Find optimal u[0], ..., u[N-1] that minimize J subject to constraints."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Apply"}),": Use only u[0], discard rest, replan next step."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"3-mpc-vs-pid",children:"3. MPC vs PID"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Aspect"}),(0,r.jsx)(n.th,{children:"PID"}),(0,r.jsx)(n.th,{children:"MPC"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Planning"})}),(0,r.jsx)(n.td,{children:"Reactive (current error)"}),(0,r.jsx)(n.td,{children:"Predictive (future horizon)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Constraints"})}),(0,r.jsx)(n.td,{children:"Hard to enforce"}),(0,r.jsx)(n.td,{children:"Natural (optimization constraints)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Optimality"})}),(0,r.jsx)(n.td,{children:"Heuristic tuning"}),(0,r.jsx)(n.td,{children:"Optimal over horizon"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Computation"})}),(0,r.jsx)(n.td,{children:"Very fast"}),(0,r.jsx)(n.td,{children:"Slower (solve optimization)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Model"})}),(0,r.jsx)(n.td,{children:"Not required"}),(0,r.jsx)(n.td,{children:"Requires system model"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use MPC"}),": Constraints critical, model available, computation affordable."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"4-implementation-steps",children:"4. Implementation Steps"}),"\n",(0,r.jsx)(n.h3,{id:"1-discretize-system",children:"1. Discretize System"}),"\n",(0,r.jsxs)(n.p,{children:["Convert continuous \u1e8b = Ax + Bu to discrete x[k+1] = A_d",(0,r.jsx)(n.em,{children:"x[k] + B_d"}),"u[k]."]}),"\n",(0,r.jsx)(n.h3,{id:"2-define-cost-function",children:"2. Define Cost Function"}),"\n",(0,r.jsx)(n.p,{children:"Quadratic: J = \u03a3 (x-x_ref)\u1d40Q(x-x_ref) + u\u1d40Ru"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Q: State cost (tracking error penalty)"}),"\n",(0,r.jsx)(n.li,{children:"R: Control cost (effort penalty)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"3-solve-optimization",children:"3. Solve Optimization"}),"\n",(0,r.jsx)(n.p,{children:"Use quadratic programming (QP) solver or gradient descent."}),"\n",(0,r.jsx)(n.h3,{id:"4-apply--repeat",children:"4. Apply & Repeat"}),"\n",(0,r.jsx)(n.p,{children:"Use first control, shift horizon, replan."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"5-exercises",children:"5. Exercises"}),"\n",(0,r.jsx)(n.h3,{id:"exercise-551-predict-future-states",children:"Exercise 5.5.1: Predict Future States"}),"\n",(0,r.jsx)(n.p,{children:"Simulate future system trajectory given control sequence."}),"\n",(0,r.jsx)(t,{id:"ex-5-5-1",title:"Predict Future States",starterCode:'import numpy as np\n\ndef predict_trajectory(x0: np.ndarray, u_sequence: np.ndarray,\n                     A: np.ndarray, B: np.ndarray) -> np.ndarray:\n  """Predict state trajectory over horizon.\n\n  System: x[k+1] = A*x[k] + B*u[k]\n\n  Args:\n      x0: Initial state (n,)\n      u_sequence: Control sequence (N, m)\n      A: State transition matrix (n, n)\n      B: Control matrix (n, m)\n\n  Returns:\n      State trajectory (N+1, n) [x0, x1, ..., xN]\n  """\n  N = len(u_sequence)\n  n = len(x0)\n  trajectory = np.zeros((N + 1, n))\n  trajectory[0] = x0\n\n  # TODO: Simulate forward dynamics\n  # For k in 0..N-1:\n  #   x[k+1] = A @ x[k] + B @ u[k]\n  pass\n\n# Test\nA = np.array([[1.0, 0.1], [0.0, 1.0]])  # Simple integrator\nB = np.array([[0.0], [0.1]])\nx0 = np.array([0.0, 0.0])\nu_sequence = np.ones((10, 1))  # Constant control\n\ntraj = predict_trajectory(x0, u_sequence, A, B)\nprint(f"Final state: {traj[-1]}")\n',hints:["for k in range(N):","trajectory[k+1] = A @ trajectory[k] + B @ u_sequence[k]","return trajectory"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"exercise-552-simple-mpc-unconstrained",children:"Exercise 5.5.2: Simple MPC (Unconstrained)"}),"\n",(0,r.jsx)(n.p,{children:"Implement basic MPC without constraints."}),"\n",(0,r.jsx)(t,{id:"ex-5-5-2",title:"Unconstrained MPC",starterCode:'import numpy as np\n\ndef simple_mpc(x_current: np.ndarray, x_ref: np.ndarray,\n             A: np.ndarray, B: np.ndarray,\n             Q: np.ndarray, R: float, N: int) -> float:\n  """Simple MPC without constraints (analytical solution).\n\n  For 1D system, minimize: J = \u03a3 Q*(x[k]-x_ref)\xb2 + R*u[k]\xb2\n\n  Args:\n      x_current: Current state (scalar)\n      x_ref: Reference state (scalar)\n      A, B: System matrices (scalars for 1D)\n      Q, R: Cost weights\n      N: Horizon length\n\n  Returns:\n      Optimal first control u[0]\n  """\n  # Simplified: For 1D system, use analytical MPC solution\n  # u[0] \u2248 K * (x_ref - x_current) where K depends on Q, R, A, B, N\n\n  # TODO: Implement simple proportional-like MPC\n  # Hint: For small horizon, acts like high-gain feedback\n  # K = Q / (R + B\xb2*Q)  (simplified)\n  pass\n\n# Test\nx_current = 0.5\nx_ref = 1.0\nA, B = 1.0, 0.1\nQ, R = 1.0, 0.01\nN = 10\n\nu = simple_mpc(x_current, x_ref, A, B, Q, R, N)\nprint(f"Optimal control: {u:.3f}")\n',hints:["error = x_ref - x_current","K = Q / (R + B**2 * Q)  # Simplified gain","return K * error"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"exercise-553-mpc-with-constraints",children:"Exercise 5.5.3: MPC with Constraints"}),"\n",(0,r.jsx)(n.p,{children:"Implement MPC with control saturation."}),"\n",(0,r.jsx)(t,{id:"ex-5-5-3",title:"MPC with Control Constraints",starterCode:'import numpy as np\n\ndef mpc_with_constraints(x_current: float, x_ref: float,\n                       A: float, B: float, Q: float, R: float,\n                       u_min: float, u_max: float, N: int) -> float:\n  """MPC with control saturation constraints.\n\n  Args:\n      x_current: Current state\n      x_ref: Reference state\n      A, B: System dynamics (scalars)\n      Q, R: Cost weights\n      u_min, u_max: Control limits\n      N: Horizon length\n\n  Returns:\n      Optimal first control u[0] (saturated)\n  """\n  # Simplified: Compute unconstrained control, then saturate\n  error = x_ref - x_current\n  K = Q / (R + B**2 * Q)\n  u_unconstrained = K * error\n\n  # TODO: Apply saturation constraints\n  # Clamp u between u_min and u_max\n  # Hint: np.clip(u, u_min, u_max)\n  pass\n\n# Test\nx_current = 0.0\nx_ref = 2.0\nA, B = 1.0, 0.1\nQ, R = 1.0, 0.01\nu_min, u_max = -1.0, 1.0\nN = 10\n\nu = mpc_with_constraints(x_current, x_ref, A, B, Q, R, u_min, u_max, N)\nprint(f"Saturated control: {u:.3f} (limits: [{u_min}, {u_max}])")\n',hints:["u_saturated = np.clip(u_unconstrained, u_min, u_max)","return u_saturated"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"6-try-with-ai",children:"6. Try With AI"}),"\n",(0,r.jsx)(n.h3,{id:"trywithai-551-when-to-use-mpc",children:"TryWithAI 5.5.1: When to Use MPC"}),"\n",(0,r.jsx)(o,{id:"tryai-5-5-1",title:"MPC vs PID Decision Making",role:"Teacher",scenario:"You need to choose between MPC and PID for a control problem",yourTask:"Describe your system and propose MPC or PID, then validate choice",aiPromptTemplate:"I have a [describe system: e.g., '2-DOF robot arm with joint limits and obstacle avoidance']. I think [MPC/PID] is better because [your reasoning: constraints, computation, model availability]. Can you: (1) Validate my choice? (2) Explain scenarios where my choice would fail? (3) Suggest hybrid approaches (e.g., PID with feedforward)?",successCriteria:["You can identify when constraints make MPC necessary","You understand computation trade-offs (real-time feasibility)","You recognize when simple PID is sufficient"],reflectionQuestions:["How fast must MPC solve optimization to run at 100 Hz control rate?","Can MPC work without a perfect model? What happens with model mismatch?","What is explicit MPC and when is it useful?"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Key Takeaways"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"MPC = Optimize over future horizon"}),": Plan ahead, apply first action, repeat"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Receding horizon"}),": Re-solve optimization at each time step"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Natural constraints"}),": Encode limits in optimization (u_min, u_max, etc.)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cost function"}),": Balance tracking (Q) and control effort (R)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Trade-offs"}),": Optimality + constraints vs computation cost"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"vs PID"}),": MPC handles constraints, requires model; PID is fast, simple"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"What's Next"}),": ",(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/physical-ai-book/ur/docs/chapter-05/quiz",children:"Chapter 5 Quiz"})})," - Test your understanding of motion planning and control!"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Estimated completion time"}),": 60 minutes | ",(0,r.jsx)(n.strong,{children:"Prerequisites"}),": Lesson 5.4 | ",(0,r.jsx)(n.strong,{children:"Difficulty"}),": B2 (Upper Intermediate)"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}function p(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var i=t(6540);const r={},s=i.createContext(r);function o(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);