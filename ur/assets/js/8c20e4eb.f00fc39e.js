if(void 0===__webpack_require__)var __webpack_require__={};(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[6780],{3638:e=>{e.exports=JSON.parse('{"tag":{"label":"vla","permalink":"/physical-ai-book/ur/docs/tags/vla","allTagsPath":"/physical-ai-book/ur/docs/tags","count":5,"items":[{"id":"chapter-07/lesson-01-whisper-voice","title":"Lesson 7.1: Voice-to-Action with OpenAI Whisper","description":"Learn to use OpenAI Whisper for speech recognition and voice command processing","permalink":"/physical-ai-book/ur/docs/chapter-07/lesson-01-whisper-voice"},{"id":"chapter-07/lesson-02-llm-planning","title":"Lesson 7.2: LLM-Based Cognitive Planning","description":"Use GPT models to translate natural language into structured robot action plans","permalink":"/physical-ai-book/ur/docs/chapter-07/lesson-02-llm-planning"},{"id":"chapter-07/lesson-03-nl-to-ros2","title":"Lesson 7.3: Natural Language to ROS 2 Actions","description":"Bridge natural language plans to executable ROS 2 actions and services","permalink":"/physical-ai-book/ur/docs/chapter-07/lesson-03-nl-to-ros2"},{"id":"chapter-07/lesson-04-multimodal","title":"Lesson 7.4: Multi-Modal Interaction","description":"Combine speech, vision, and gesture for natural human-robot interaction","permalink":"/physical-ai-book/ur/docs/chapter-07/lesson-04-multimodal"},{"id":"chapter-07/lesson-05-capstone","title":"Lesson 7.5: Capstone Project - The Autonomous Humanoid","description":"Build a complete autonomous humanoid system with VLA pipeline","permalink":"/physical-ai-book/ur/docs/chapter-07/lesson-05-capstone"}],"unlisted":false}}')}}]);