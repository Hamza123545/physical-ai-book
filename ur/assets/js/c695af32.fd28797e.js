if(void 0===__webpack_require__)var __webpack_require__={};(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[2884],{8453:(e,s,n)=>{n.d(s,{R:()=>r,x:()=>l});var t=n(6540);const a={},i=t.createContext(a);function r(e){const s=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function l(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),t.createElement(i.Provider,{value:s},e.children)}},8821:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>l,default:()=>d,frontMatter:()=>r,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"appendices/appendix-b-computer-vision-fundamentals/lesson-03-object-detection","title":"Lesson 3.3: Object Detection and Tracking","description":"Segment, detect, and track objects using color-based methods and centroids","source":"@site/i18n/ur/docusaurus-plugin-content-docs/current/appendices/appendix-b-computer-vision-fundamentals/lesson-03-object-detection.md","sourceDirName":"appendices/appendix-b-computer-vision-fundamentals","slug":"/appendices/appendix-b-computer-vision-fundamentals/lesson-03-object-detection","permalink":"/physical-ai-book/ur/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-03-object-detection","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"object-detection","permalink":"/physical-ai-book/ur/docs/tags/object-detection"},{"inline":true,"label":"color-segmentation","permalink":"/physical-ai-book/ur/docs/tags/color-segmentation"},{"inline":true,"label":"centroids","permalink":"/physical-ai-book/ur/docs/tags/centroids"},{"inline":true,"label":"tracking","permalink":"/physical-ai-book/ur/docs/tags/tracking"}],"version":"current","frontMatter":{"title":"Lesson 3.3: Object Detection and Tracking","description":"Segment, detect, and track objects using color-based methods and centroids","chapter":3,"lesson":3,"estimated_time":70,"cefr_level":"B2","blooms_level":"Apply","digcomp_level":5,"generated_by":"claude-sonnet-4-5-20250929","source_spec":"specs/002-physical-ai-textbook/spec.md","created":"2025-11-29","last_modified":"2025-11-29","git_author":"hswat","workflow":"/sp.implement","version":"1.0","prerequisites":["chapter-03-lesson-01"],"has_interactive_python":true,"interactive_python_count":4,"has_try_with_ai":true,"try_with_ai_count":2,"tags":["object-detection","color-segmentation","centroids","tracking"]},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 3.2: Edge and Corner Detection","permalink":"/physical-ai-book/ur/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-02-edge-detection"},"next":{"title":"Lesson 3.4: Depth Perception and Obstacles","permalink":"/physical-ai-book/ur/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-04-depth-perception"}}');var a=n(4848),i=n(8453);const r={title:"Lesson 3.3: Object Detection and Tracking",description:"Segment, detect, and track objects using color-based methods and centroids",chapter:3,lesson:3,estimated_time:70,cefr_level:"B2",blooms_level:"Apply",digcomp_level:5,generated_by:"claude-sonnet-4-5-20250929",source_spec:"specs/002-physical-ai-textbook/spec.md",created:"2025-11-29",last_modified:"2025-11-29",git_author:"hswat",workflow:"/sp.implement",version:"1.0",prerequisites:["chapter-03-lesson-01"],has_interactive_python:!0,interactive_python_count:4,has_try_with_ai:!0,try_with_ai_count:2,tags:["object-detection","color-segmentation","centroids","tracking"]},l="Lesson 3.3: Object Detection and Tracking",c={},o=[{value:"\ud83c\udfaf Learning Objectives",id:"-learning-objectives",level:2},{value:"\ud83d\udcda Prerequisites",id:"-prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"1. Color-Based Segmentation",id:"1-color-based-segmentation",level:2},{value:"2. Centroid Computation",id:"2-centroid-computation",level:2},{value:"3. Object Tracking",id:"3-object-tracking",level:2},{value:"4. Exercises",id:"4-exercises",level:2},{value:"Exercise 3.3.1: Color-Based Segmentation",id:"exercise-331-color-based-segmentation",level:3},{value:"Exercise 3.3.2: Compute Centroid",id:"exercise-332-compute-centroid",level:3},{value:"Exercise 3.3.3: Object Orientation",id:"exercise-333-object-orientation",level:3},{value:"Exercise 3.3.4: Simple Object Tracking",id:"exercise-334-simple-object-tracking",level:3},{value:"5. Try With AI",id:"5-try-with-ai",level:2},{value:"TryWithAI 3.3.1: Object Detection Implementation",id:"trywithai-331-object-detection-implementation",level:3},{value:"TryWithAI 3.3.2: Tracking Robustness",id:"trywithai-332-tracking-robustness",level:3},{value:"Summary",id:"summary",level:2}];function m(e){const s={a:"a",annotation:"annotation",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mo:"mo",mrow:"mrow",mspace:"mspace",msub:"msub",ol:"ol",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{InteractivePython:n,LearningObjectives:t,Prerequisites:r,TryWithAI:l}=s;return n||h("InteractivePython",!0),t||h("LearningObjectives",!0),r||h("Prerequisites",!0),l||h("TryWithAI",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(s.header,{children:(0,a.jsx)(s.h1,{id:"lesson-33-object-detection-and-tracking",children:"Lesson 3.3: Object Detection and Tracking"})}),"\n",(0,a.jsx)(s.h2,{id:"-learning-objectives",children:"\ud83c\udfaf Learning Objectives"}),"\n",(0,a.jsx)(t,{cefr_level:"B2",objectives:[{text:"Segment objects using color-based thresholds",blooms_level:"Apply",assessment_method:"Color segmentation exercise"},{text:"Compute object centroids for position estimation",blooms_level:"Apply",assessment_method:"Centroid calculation exercise"},{text:"Track objects across video frames",blooms_level:"Apply",assessment_method:"Object tracking exercise"}]}),"\n",(0,a.jsx)(s.h2,{id:"-prerequisites",children:"\ud83d\udcda Prerequisites"}),"\n",(0,a.jsx)(r,{prerequisites:[{lessonId:"chapter-03-lesson-01",title:"Lesson 3.1: Image Representation",link:"/docs/chapter-03/lesson-01-image-representation"}]}),"\n",(0,a.jsx)(s.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsxs)(s.p,{children:["Robots need to ",(0,a.jsx)(s.strong,{children:"find"})," and ",(0,a.jsx)(s.strong,{children:"track"})," objects to manipulate them or avoid them. This lesson covers:"]}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"Color-based segmentation to isolate objects"}),"\n",(0,a.jsx)(s.li,{children:"Computing object centroids (center of mass)"}),"\n",(0,a.jsx)(s.li,{children:"Tracking objects over time"}),"\n"]}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Time"}),": 70 minutes"]}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h2,{id:"1-color-based-segmentation",children:"1. Color-Based Segmentation"}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Idea"}),": Objects often have distinct colors. Segment by filtering color ranges."]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"# Find red pixels\nred_mask = (image[:,:,0] > 200) & (image[:,:,1] < 50) & (image[:,:,2] < 50)\n"})}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h2,{id:"2-centroid-computation",children:"2. Centroid Computation"}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Centroid"})," = center of mass of an object:"]}),"\n",(0,a.jsx)(s.span,{className:"katex-display",children:(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"x"}),(0,a.jsx)(s.mi,{children:"c"})]}),(0,a.jsx)(s.mo,{children:"="}),(0,a.jsxs)(s.mfrac,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mo,{children:"\u2211"}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"x"}),(0,a.jsx)(s.mi,{children:"i"})]})]}),(0,a.jsx)(s.mi,{children:"N"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsx)(s.mspace,{width:"1em"}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"y"}),(0,a.jsx)(s.mi,{children:"c"})]}),(0,a.jsx)(s.mo,{children:"="}),(0,a.jsxs)(s.mfrac,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mo,{children:"\u2211"}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"y"}),(0,a.jsx)(s.mi,{children:"i"})]})]}),(0,a.jsx)(s.mi,{children:"N"})]})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"x_c = \\frac{\\sum x_i}{N}, \\quad y_c = \\frac{\\sum y_i}{N}"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"x"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.1514em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"c"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"="}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"2.113em",verticalAlign:"-0.686em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mopen nulldelimiter"}),(0,a.jsx)(s.span,{className:"mfrac",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"1.427em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.314em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord",children:(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.10903em"},children:"N"})})]}),(0,a.jsxs)(s.span,{style:{top:"-3.23em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"frac-line",style:{borderBottomWidth:"0.04em"}})]}),(0,a.jsxs)(s.span,{style:{top:"-3.677em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mop op-symbol small-op",style:{position:"relative",top:"0em"},children:"\u2211"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"x"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3117em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]})]})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.686em"},children:(0,a.jsx)(s.span,{})})})]})}),(0,a.jsx)(s.span,{className:"mclose nulldelimiter"})]}),(0,a.jsx)(s.span,{className:"mpunct",children:","}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"1em"}}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"y"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.1514em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0359em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"c"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"="}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"2.113em",verticalAlign:"-0.686em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mopen nulldelimiter"}),(0,a.jsx)(s.span,{className:"mfrac",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"1.427em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.314em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord",children:(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.10903em"},children:"N"})})]}),(0,a.jsxs)(s.span,{style:{top:"-3.23em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"frac-line",style:{borderBottomWidth:"0.04em"}})]}),(0,a.jsxs)(s.span,{style:{top:"-3.677em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mop op-symbol small-op",style:{position:"relative",top:"0em"},children:"\u2211"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"y"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3117em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0359em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]})]})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.686em"},children:(0,a.jsx)(s.span,{})})})]})}),(0,a.jsx)(s.span,{className:"mclose nulldelimiter"})]})]})]})]})}),"\n",(0,a.jsxs)(s.p,{children:["Where ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mo,{stretchy:"false",children:"("}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"x"}),(0,a.jsx)(s.mi,{children:"i"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"y"}),(0,a.jsx)(s.mi,{children:"i"})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:")"})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"(x_i, y_i)"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,a.jsx)(s.span,{className:"mopen",children:"("}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"x"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3117em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mpunct",children:","}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"y"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3117em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0359em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mclose",children:")"})]})})]})," are object pixels."]}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h2,{id:"3-object-tracking",children:"3. Object Tracking"}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Simple tracking"}),": Match centroids between frames (nearest neighbor)."]}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h2,{id:"4-exercises",children:"4. Exercises"}),"\n",(0,a.jsx)(s.h3,{id:"exercise-331-color-based-segmentation",children:"Exercise 3.3.1: Color-Based Segmentation"}),"\n",(0,a.jsx)(n,{id:"ex-3-3-1",title:"Color Segmentation",starterCode:'import numpy as np\nimport matplotlib.pyplot as plt\n\ndef segment_by_color(image, color_min, color_max):\n  """Segment objects by color range."""\n  # TODO: Create mask where all channels are in range\n  pass\n\n# Test\nimg = np.zeros((100, 100, 3), dtype=np.uint8)\nimg[20:40, 20:40] = [255, 0, 0]  # Red square\n\nmask = segment_by_color(img, [200, 0, 0], [255, 50, 50])\nplt.imshow(mask, cmap=\'gray\')\nplt.show()\n',hints:["mask = np.all((image >= color_min) & (image <= color_max), axis=2)","Return mask.astype(np.uint8) * 255"]}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h3,{id:"exercise-332-compute-centroid",children:"Exercise 3.3.2: Compute Centroid"}),"\n",(0,a.jsx)(n,{id:"ex-3-3-2",title:"Object Centroid",starterCode:'import numpy as np\n\ndef compute_centroid(binary_mask):\n  """Compute centroid of binary object."""\n  # TODO: Find y, x coordinates of True pixels\n  # Return mean(x), mean(y)\n  pass\n\n# Test\nmask = np.zeros((100, 100), dtype=bool)\nmask[40:60, 30:50] = True\n\ncx, cy = compute_centroid(mask)\nprint(f"Centroid: ({cx:.1f}, {cy:.1f})")\nprint(f"Expected: (40.0, 50.0)")\n',hints:["y_coords, x_coords = np.where(binary_mask)","cx = np.mean(x_coords)","cy = np.mean(y_coords)","return cx, cy"]}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h3,{id:"exercise-333-object-orientation",children:"Exercise 3.3.3: Object Orientation"}),"\n",(0,a.jsx)(n,{id:"ex-3-3-3",title:"Object Orientation Angle",starterCode:'import numpy as np\n\ndef compute_orientation(binary_mask):\n  """Compute object orientation using moments."""\n  # TODO: Compute second moments and orientation\n  pass\n\n# Test\nmask = np.zeros((100, 100), dtype=bool)\nfor i in range(30, 70):\n  mask[i, i] = True  # Diagonal line\n\nangle = compute_orientation(mask)\nprint(f"Orientation: {angle:.1f} degrees")\nprint(f"Expected: ~45 degrees")\n',hints:["y, x = np.where(binary_mask)","cx, cy = np.mean(x), np.mean(y)","x_centered = x - cx","y_centered = y - cy","angle = np.arctan2(y_centered.sum(), x_centered.sum())","return np.degrees(angle)"]}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h3,{id:"exercise-334-simple-object-tracking",children:"Exercise 3.3.4: Simple Object Tracking"}),"\n",(0,a.jsx)(n,{id:"ex-3-3-4",title:"Track Object Across Frames",starterCode:'import numpy as np\n\ndef track_object(centroids_frame1, centroids_frame2, max_distance=50):\n  """Match objects between frames using nearest neighbor."""\n  # TODO: For each centroid in frame1, find nearest in frame2\n  # Return list of matches: [(idx1, idx2), ...]\n  pass\n\n# Test\nframe1_centroids = [(50, 50), (100, 100)]\nframe2_centroids = [(55, 52), (102, 98)]  # Slightly moved\n\nmatches = track_object(frame1_centroids, frame2_centroids)\nprint(f"Matches: {matches}")\nprint(f"Expected: [(0, 0), (1, 1)]")\n',hints:["For each c1 in centroids_frame1:","  distances = [np.linalg.norm(np.array(c1) - np.array(c2)) for c2 in centroids_frame2]","  nearest_idx = np.argmin(distances)","  if distances[nearest_idx] < max_distance:","    matches.append((i, nearest_idx))"]}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h2,{id:"5-try-with-ai",children:"5. Try With AI"}),"\n",(0,a.jsx)(s.h3,{id:"trywithai-331-object-detection-implementation",children:"TryWithAI 3.3.1: Object Detection Implementation"}),"\n",(0,a.jsx)(l,{id:"tryai-3-3-1",title:"Robust Color Segmentation",role:"Copilot",scenario:"Your color-based object detector fails under different lighting conditions.",yourTask:"Implement Exercise 3.3.1. Test with images at different brightnesses. Notice failures.",aiPromptTemplate:"My color segmentation works in good lighting but fails when lighting changes. Here's my code: [paste]. Can you help me make it more robust? Should I use HSV color space instead of RGB? How do I handle shadows and highlights?",successCriteria:["You understand RGB vs HSV for color segmentation","You can handle lighting variations","You know when color-based methods fail"],reflectionQuestions:["When should you use HSV instead of RGB?","How do you handle objects with multiple colors?","What are alternatives to color-based detection?"]}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h3,{id:"trywithai-332-tracking-robustness",children:"TryWithAI 3.3.2: Tracking Robustness"}),"\n",(0,a.jsx)(l,{id:"tryai-3-3-2",title:"Improve Object Tracking",role:"Evaluator",scenario:"Your tracker loses objects when they move quickly or overlap.",yourTask:"Complete Exercise 3.3.4. Think about failure cases: fast motion, occlusion, multiple objects.",aiPromptTemplate:"My object tracker uses nearest-neighbor matching. Here's my code: [paste]. It fails when: (1) Objects move > 50 pixels between frames, (2) Objects overlap. Can you review and suggest improvements? Should I use Kalman filtering? How do I handle occlusion?",successCriteria:["You understand limitations of nearest-neighbor tracking","You know about prediction-based tracking (Kalman filter)","You can handle edge cases (occlusion, fast motion)"],reflectionQuestions:["How would you track multiple objects of the same color?","What's the role of prediction in tracking?","When should you re-initialize tracking?"]}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsx)(s.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Key Takeaways"}),":"]}),"\n",(0,a.jsxs)(s.ol,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Color Segmentation"}),": Filter by RGB/HSV ranges to isolate objects"]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Centroids"}),": Compute center of mass for object position"]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Tracking"}),": Match objects between frames using nearest neighbor"]}),"\n"]}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"What's Next"}),": ",(0,a.jsx)(s.a,{href:"/physical-ai-book/ur/docs/appendices/appendix-b-computer-vision-fundamentals/lesson-04-depth-perception",children:"Lesson 3.4: Depth Perception"})]}),"\n",(0,a.jsx)(s.hr,{}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Estimated completion time"}),": 70 minutes | ",(0,a.jsx)(s.strong,{children:"Difficulty"}),": B2"]})]})}function d(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}function h(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}}}]);