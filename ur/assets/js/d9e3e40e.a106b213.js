if(void 0===__webpack_require__)var __webpack_require__={};(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[6544],{6107:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"chapter-07/lesson-03-nl-to-ros2","title":"Lesson 7.3: Natural Language to ROS 2 Actions","description":"Bridge natural language plans to executable ROS 2 actions and services","source":"@site/i18n/ur/docusaurus-plugin-content-docs/current/chapter-07/lesson-03-nl-to-ros2.md","sourceDirName":"chapter-07","slug":"/chapter-07/lesson-03-nl-to-ros2","permalink":"/physical-ai-book/ur/docs/chapter-07/lesson-03-nl-to-ros2","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"ros2","permalink":"/physical-ai-book/ur/docs/tags/ros-2"},{"inline":true,"label":"actions","permalink":"/physical-ai-book/ur/docs/tags/actions"},{"inline":true,"label":"nl-to-code","permalink":"/physical-ai-book/ur/docs/tags/nl-to-code"},{"inline":true,"label":"vla","permalink":"/physical-ai-book/ur/docs/tags/vla"},{"inline":true,"label":"integration","permalink":"/physical-ai-book/ur/docs/tags/integration"}],"version":"current","frontMatter":{"title":"Lesson 7.3: Natural Language to ROS 2 Actions","description":"Bridge natural language plans to executable ROS 2 actions and services","chapter":7,"lesson":3,"estimated_time":60,"cefr_level":"B2","blooms_level":"Apply","digcomp_level":5,"generated_by":"claude-sonnet-4-5-20250929","source_spec":"specs/002-physical-ai-textbook/spec.md","created":"2025-11-29","last_modified":"2025-11-29","git_author":"hswat","workflow":"/sp.implement","version":"1.0","prerequisites":["chapter-07-lesson-02","chapter-02-lesson-03"],"has_interactive_python":true,"interactive_python_count":1,"has_try_with_ai":false,"try_with_ai_count":0,"tags":["ros2","actions","nl-to-code","vla","integration"]},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 7.2: LLM-Based Cognitive Planning","permalink":"/physical-ai-book/ur/docs/chapter-07/lesson-02-llm-planning"},"next":{"title":"Lesson 7.4: Multi-Modal Interaction","permalink":"/physical-ai-book/ur/docs/chapter-07/lesson-04-multimodal"}}');var i=t(4848),a=t(8453);const s={title:"Lesson 7.3: Natural Language to ROS 2 Actions",description:"Bridge natural language plans to executable ROS 2 actions and services",chapter:7,lesson:3,estimated_time:60,cefr_level:"B2",blooms_level:"Apply",digcomp_level:5,generated_by:"claude-sonnet-4-5-20250929",source_spec:"specs/002-physical-ai-textbook/spec.md",created:"2025-11-29",last_modified:"2025-11-29",git_author:"hswat",workflow:"/sp.implement",version:"1.0",prerequisites:["chapter-07-lesson-02","chapter-02-lesson-03"],has_interactive_python:!0,interactive_python_count:1,has_try_with_ai:!1,try_with_ai_count:0,tags:["ros2","actions","nl-to-code","vla","integration"]},r="Lesson 7.3: Natural Language to ROS 2 Actions",l={},c=[{value:"\ud83c\udfaf Learning Objectives",id:"-learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"1. Action Translation",id:"1-action-translation",level:2},{value:"Plan to ROS 2 Actions",id:"plan-to-ros-2-actions",level:3},{value:"2. ROS 2 Action Clients",id:"2-ros-2-action-clients",level:2},{value:"Navigation Action",id:"navigation-action",level:3},{value:"3. Error Handling",id:"3-error-handling",level:2},{value:"Robust Execution",id:"robust-execution",level:3},{value:"4. Progress Monitoring",id:"4-progress-monitoring",level:2},{value:"Action Feedback",id:"action-feedback",level:3},{value:"5. Exercises",id:"5-exercises",level:2},{value:"Exercise 7.3.1: Action Translator",id:"exercise-731-action-translator",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components},{InteractivePython:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("InteractivePython",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"lesson-73-natural-language-to-ros-2-actions",children:"Lesson 7.3: Natural Language to ROS 2 Actions"})}),"\n",(0,i.jsx)(n.h2,{id:"-learning-objectives",children:"\ud83c\udfaf Learning Objectives"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Convert LLM-generated plans to ROS 2 actions"}),"\n",(0,i.jsx)(n.li,{children:"Implement action execution with error handling"}),"\n",(0,i.jsx)(n.li,{children:"Validate commands before execution"}),"\n",(0,i.jsx)(n.li,{children:"Monitor action progress and provide feedback"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Time"}),": 60 minutes"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(n.p,{children:"This lesson bridges the gap between LLM-generated plans and actual robot execution. You'll learn to translate structured action sequences into ROS 2 action calls, handle errors, and provide feedback."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Key Challenge"}),": LLMs generate high-level plans, but robots need low-level ROS 2 commands."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"1-action-translation",children:"1. Action Translation"}),"\n",(0,i.jsx)(n.h3,{id:"plan-to-ros-2-actions",children:"Plan to ROS 2 Actions"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class ActionExecutor:\n    def __init__(self, node):\n        self.node = node\n        self.nav_action_client = ActionClient(node, NavigateToPose, \'navigate_to_pose\')\n        self.pick_action_client = ActionClient(node, PickObject, \'pick_object\')\n        \n    def execute_plan(self, plan):\n        """Execute LLM-generated plan."""\n        for action in plan["actions"]:\n            result = self.execute_action(action)\n            if not result.success:\n                return False\n        return True\n    \n    def execute_action(self, action):\n        """Execute single action."""\n        action_type = action["type"]\n        \n        if action_type == "navigate":\n            return self.navigate(action["target"])\n        elif action_type == "pick":\n            return self.pick_object(action["object"])\n        elif action_type == "place":\n            return self.place_object(action["object"], action["location"])\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"2-ros-2-action-clients",children:"2. ROS 2 Action Clients"}),"\n",(0,i.jsx)(n.h3,{id:"navigation-action",children:"Navigation Action"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from nav2_msgs.action import NavigateToPose\n\ndef navigate_to_pose(self, target_pose):\n    """Execute navigation action."""\n    goal_msg = NavigateToPose.Goal()\n    goal_msg.pose = target_pose\n    \n    self.nav_action_client.wait_for_server()\n    send_goal_future = self.nav_action_client.send_goal_async(goal_msg)\n    \n    # Wait for result\n    rclpy.spin_until_future_complete(self.node, send_goal_future)\n    goal_handle = send_goal_future.result()\n    \n    if not goal_handle.accepted:\n        return False\n    \n    # Get result\n    result_future = goal_handle.get_result_async()\n    rclpy.spin_until_future_complete(self.node, result_future)\n    return result_future.result().result\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"3-error-handling",children:"3. Error Handling"}),"\n",(0,i.jsx)(n.h3,{id:"robust-execution",children:"Robust Execution"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def safe_execute_action(self, action, max_retries=3):\n    """Execute action with retry logic."""\n    for attempt in range(max_retries):\n        try:\n            result = self.execute_action(action)\n            if result.success:\n                return True\n            else:\n                self.node.get_logger().warn(\n                    f"Action failed: {result.error_message}"\n                )\n        except Exception as e:\n            self.node.get_logger().error(f"Exception: {e}")\n        \n        if attempt < max_retries - 1:\n            time.sleep(1)  # Wait before retry\n    \n    return False\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"4-progress-monitoring",children:"4. Progress Monitoring"}),"\n",(0,i.jsx)(n.h3,{id:"action-feedback",children:"Action Feedback"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'def execute_with_feedback(self, action):\n    """Execute action and provide feedback."""\n    goal_handle = self.send_action_goal(action)\n    \n    # Monitor feedback\n    while not goal_handle.is_done():\n        feedback = goal_handle.get_feedback()\n        self.node.get_logger().info(\n            f"Progress: {feedback.current_pose}"\n        )\n        time.sleep(0.1)\n    \n    return goal_handle.result()\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"5-exercises",children:"5. Exercises"}),"\n",(0,i.jsx)(n.h3,{id:"exercise-731-action-translator",children:"Exercise 7.3.1: Action Translator"}),"\n",(0,i.jsx)(n.p,{children:"Convert LLM plan to ROS 2 action calls."}),"\n",(0,i.jsx)(t,{id:"ex-7-3-1",title:"Plan to ROS 2 Actions",starterCode:'def translate_plan_to_ros2(plan):\n  """\n  Convert LLM plan to ROS 2 action calls.\n  \n  Args:\n      plan: Dict with "actions" list\n  \n  Returns:\n      List of ROS 2 action call descriptions\n  """\n  # TODO: Translate each action to ROS 2 format\n  pass\n\n# Test\nplan = {\n  "actions": [\n      {"type": "navigate", "target": "kitchen"},\n      {"type": "pick", "object": "cup"},\n      {"type": "place", "object": "cup", "location": "sink"}\n  ]\n}\n\nros2_actions = translate_plan_to_ros2(plan)\nprint(ros2_actions)\n',hints:["Map action types to ROS 2 action names","Convert parameters to ROS 2 message format","Include error handling structure"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Key Takeaways"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"LLM plans must be translated to ROS 2 actions"}),"\n",(0,i.jsx)(n.li,{children:"Action clients execute goals asynchronously"}),"\n",(0,i.jsx)(n.li,{children:"Error handling and retries improve robustness"}),"\n",(0,i.jsx)(n.li,{children:"Progress monitoring provides user feedback"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"What's Next"}),": ",(0,i.jsx)(n.a,{href:"/physical-ai-book/ur/docs/chapter-07/lesson-04-multimodal",children:"Lesson 7.4: Multi-Modal Interaction"})," combines speech, vision, and gesture."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Estimated completion time"}),": 60 minutes | ",(0,i.jsx)(n.strong,{children:"Prerequisites"}),": Lesson 7.2, Chapter 2 (ROS 2) | ",(0,i.jsx)(n.strong,{children:"Difficulty"}),": B2 (Advanced)"]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var o=t(6540);const i={},a=o.createContext(i);function s(e){const n=o.useContext(a);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),o.createElement(a.Provider,{value:n},e.children)}}}]);